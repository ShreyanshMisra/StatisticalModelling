---
title: "Time Series on Apple Stock Prices"
output:
  html_document:
    df_print: paged
  pdf_document:
    number_sections: true
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(quantmod)
library(lmtest)
library(dplyr)
library(ggplot2)
library(xts)
library(tidyverse)
library("lubridate")
library("gridExtra")
library(tseries)
library(forecast)
library(PerformanceAnalytics)
library(rugarch)
```

# Introduction

Apple is a technology company headquartered in Silicon Valley. It is best known for its consumer electronics, software, and services. We seek to predict the stock price movements of Apple (NASDAQ: AAPL) given it is one of the largest companies by market cap ($3.2Tn) and one of the most heavily traded / liquid stocks. 

In order to predict the stock price, we will build multiple models. The two types of model will be Auto Regressive-Moving Average (ARMA) and Generalized Autoregressive Conditional Heteroskedasticity (GARCH). Each model will have a different lag component either selected or derived from ARC and PARC analysis. 

We used a ARMA(3,2)-eGARCH(1,1) model to predict AAPL's stock price movements. The model was selected as it had the lowest AIC of the 8 models we tested. The 8 models had common AR(p)-MA(q) parameters given the ARC and PARC graphs. While our forecasted stock price varies from the observed stock price, this was largely the result of recent market events - tariffs and geopolitical conflict between AAPL's two most important markets (US & China). We believe the model will perform better in times of normalized market activities.  

# Data description

The dataset includes Apple financial data from December 1980 to to April 2025. The data was extracted from Yahoo Finance which is an open source Financial data source. 

```{r}
getSymbols("AAPL", src="yahoo", periodicity = "daily", from = "1980-12-15", to = "2025-04-25")
```

## Variables

- Date: Trading day
- Open: Price at market open.
- High: Highest price that day.
- Low: Lowest price that day.
- Close: Price at market close.
- Volume: Shares traded that day.
- Adjusted: Close price adjusted for splits/dividends.

## Dataset

```{r }
head(AAPL)
```

```{r }
data <- cbind(
  Price = AAPL$AAPL.Close,
  Return=CalculateReturns(AAPL$AAPL.Close, method = 'log'))
colnames(data) <- c('Price','Return')
head(data)
```

# Analysis

## Exploratory Data Analysis
```{r }
plot(na.omit(data$Price), ylab='AAPL Closing Price',main='Apple Stock Price from 1980-2025',col='black')
```

The Apple stock price has clerly increased over the 45 year period, even though there is some clear volatility. The stock price is definitely not stationary as the mean and variance both change over time. 

```{r}
plot(na.omit(data$Return),main='Return of AAPL')
```

The log of return series shows the Return series is stationary, so the mean and variance of Return series is constant over time.

## Testing Assumptions

For time series modelling, we assume the following:

1. Stationarity
2. Absence of Autocorrelation

We also use diagnostic tools like the Auto Correlation Function (ACF) to detect patterns in residuals, the Normality test to evaluate residuals, and Volatility Clustering to determine whether a GARCH model is appropriate.

### Checking the Stationarity of Price

```{r}
adf.test(na.omit(data$Price))
```

The Augmented Dickey-Fuller Test gave us a P-value of 0.99. Since that is higher than 0.05 so we can not reject the null hypothesis and conclude that the Price of the data is not stationary.

### Checking the Stationarity of Return

```{r}
adf.test(na.omit(data$Return))
```

After applying the ADF to test on Return series, we get a P-value of 0.01. That is lower than 0.05 so we can reject the null hypothesis and conclude that the Return of the data is stationary.

Since Return is stationary, we can use that as our measure for this investigation. This agrees with most financial studies which use returns instead of price.

### Auto Correlation Function

```{r}
acf(na.omit(data$Return), lag.max = 40, main='ACF of Return Values',col='red')
```

```{r}
pacf(na.omit(data$Return), main='Partial Auto Correlation of Return Values',col='red')
```

### Stylized Facts of Financial Data

```{r}
ggplot(aes(Return), data=data) + geom_histogram(bins = 100,col='black',fill='red') + ggtitle('Return of AAPL')
```

```{r}
skewness(data$Return); kurtosis(data$Return)
```

```{r}
ggplot(data=data, aes(sample = Return)) +
  stat_qq() +
  stat_qq_line(col='red') + ggtitle('QQ plot of AAPL Returns')
```

### Normality Test

```{r}
jarque.bera.test(na.omit(data$Return))
```

### Absence of Auto Correlation

```{r}
Box.test(na.omit(data$Return), type = "Ljung-Box")
```

### Absolute Return or Squared of Return are auto correlated

```{r}
a<- ggAcf(abs(na.omit(data$Return)), col='red',main='Acf of Log Return of AAPL')
p<- ggPacf(abs(na.omit(data$Return)),col='steelblue',main='PAcf of Log Return of AAPL')
grid.arrange(a,p, ncol = 2, nrow = 1)
```

```{r}
c <- ggAcf(na.omit(data$Return)^2, lag.max = 40, col='red', main='ACF of squared Return Values')
d<- ggPacf(na.omit(data$Return)^2,lag.max = 40, col='steelblue',main= 'PACF of squared Return Values')
grid.arrange(c,d, ncol = 2, nrow = 1)
```

Given the ACF and PACF graph gradually declines with no significant spikes / drops, there is no clear value of p for AR(p) or q for MA(q). This indicates the time series of AAPL stock exhibits both AR and MA characteristics with equally strong components. Without clear values, we will test multiple models and use an information criterion, AIC, to choose the best. 

### Volatility Clustering

```{r}
chart.RollingPerformance(na.omit(data$Return),width = 22,FUN = 'sd.annualized',scale=252, main = 'Rolling 1 month Volatility')
```

# Modelling

The GARCH (generalized autoregressive conditional heteroskedasticity) model is an approach to estimate volatility in financial markets, allowing us to predict the returns of financial assets.

## Model 1 ARMA(0,0) - gjrGARCH(1,1)

```{r}
MSF_garch_1 <- ugarchspec(mean.model = list(armaOrder=c(0,0)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_1 <- ugarchfit(spec = MSF_garch_1, data= na.omit(data$Return))
fit_garch_1
```

## Model 2 ARMA(1,1) - gjrGARCH(1,1)
```{r}
MSF_garch_2 <- ugarchspec(mean.model = list(armaOrder=c(1,1)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_2 <- ugarchfit(spec = MSF_garch_2, data= na.omit(data$Return))
fit_garch_2
```

## Model 3
```{r}
MSF_garch_3 <- ugarchspec(mean.model = list(armaOrder=c(2,2)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_3 <- ugarchfit(spec = MSF_garch_3, data= na.omit(data$Return))
fit_garch_3
```

## Model 4
```{r}
MSF_garch_4 <- ugarchspec(mean.model = list(armaOrder=c(1,2)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_4 <- ugarchfit(spec = MSF_garch_4, data= na.omit(data$Return))
fit_garch_4
```

## Model 5
```{r}
MSF_garch_5 <- ugarchspec(mean.model = list(armaOrder=c(2,1)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_5 <- ugarchfit(spec = MSF_garch_5, data= na.omit(data$Return))
fit_garch_5
```

## Model 6
```{r}
MSF_garch_6 <- ugarchspec(mean.model = list(armaOrder=c(3,1)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_6 <- ugarchfit(spec = MSF_garch_6, data= na.omit(data$Return))
fit_garch_6
```

## Model 7
```{r}
MSF_garch_7 <- ugarchspec(mean.model = list(armaOrder=c(3,2)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_7 <- ugarchfit(spec = MSF_garch_7, data= na.omit(data$Return))
fit_garch_7
```

## Model 8
```{r}
MSF_garch_8 <- ugarchspec(mean.model = list(armaOrder=c(1,3)),variance.model = list(model = 'eGARCH', 
                          garchOrder = c(1, 1)),distribution = 'std')

fit_garch_8 <- ugarchfit(spec = MSF_garch_8, data= na.omit(data$Return))
fit_garch_8
```

## Model Selection
```{r}
infocriteria(fit_garch_1)
infocriteria(fit_garch_2)
infocriteria(fit_garch_3)
infocriteria(fit_garch_4)
infocriteria(fit_garch_5)
infocriteria(fit_garch_6)
infocriteria(fit_garch_7)
infocriteria(fit_garch_8)
```

```{r}
names <- c('fit_garch_1', 'fit_garch_2', 'fit_garch_3', 'fit_garch_4', 'fit_garch_5', 'fit_garch_6', 'fit_garch_7', 'fit_garch_8')
AIC <- c(-4.694247, -4.694410, -4.695057, -4.694734, -4.694798, -4.695119, -4.695168, -4.695122)

information.df <- data.frame(names, AIC)
which.min(information.df[,'AIC'])
```

Model 7 minimizes AIC. Model 7 is an ARMA(3,2)-eGARCH(1,1) model with AIC = -4.695168. Hence, we use value 3 for autoregression and 2 for moving average. Three lags of the stock price are used to predict the next value based on the moving average of two periods. The volatility is modelling depending on the previous error and previous volatility.

We believe this longer lag makes conceptual sense. A longer lag inferes greater dependency between past and currently values, indicating a longer term relationship. Given AAPL is a "blue chip" stock, investors and the market understand it's business quality and fundamental superiority. AAPL is less impacted by idiosyncratic and one time market events. Rather, AAPL's growth story and stock price have consistently trended upward, showing a longer-term relationship and growth. 

```{r}
model <- fit_garch_7
plot(model,which='all')
```

```{r}
persistence(model)
```

The high persistence value of 0.99 indicates a high volatitlity clustering so shocks to volatility will linger for a long time and volatility decays slowly. In relation to our upcoming forecasts, this high persistence tells us that short-term forecasts will be more directly influenced by current volatility while long-term forecasts will slowly revert to the unconditional variance.

# Forecasting

## Forecasting 20 Steps Ahead

This type of forecast is a one-time prediction of the next 20 data points using your model. It tells us how well the model can project future values based purely on the last known data point (static forecast so it does not update or re-estimate the model during the forecast.).

```{r}
forecast <-ugarchforecast(model,data=data,n.ahead=20)
forecast
```

The Series value or Forecasted Return starts at -0.057% at T+1, increases to +0.094% at T+2, then stabilizes at around 0.0985% after T+3. The Sigma value or volatitlity also starts high at 0.03796 but gradually gets smaller to 0.03499 at T+20 indicating that volatility is slowly decreasing. 

## Rolling Forecast

This is a repeated one-step-ahead forecast, where the model updates with each new observation. It's a lot more realistic than the 20 Steps Ahead forecast. 

```{r}
fit_roll <- ugarchfit(MSF_garch_7, data= na.omit(data$Return),out.sample =500)
fore_roll <- ugarchforecast(fit_roll, n.ahead=20, n.roll=50)
fore_roll
```

The Rolling Forecast is a more powerful way to simulate real-time forecasting. We fit the model on all data except the last 500 points, then roll forward the model 50 times and at each roll we forecast 20 steps ahead starting from the new point. The Expected Return over the next 20 periods starts at 0.116% in T+1, fluctuates a bit, and stabilizes around 0.102%. The volatility starts at 0.01415 and rises slightly to 0.01568 over 20 steps. This increase may suggest slight volatility expansion over the forecast horizon

```{r}
par(mfrow=c(1,2))
plot(fore_roll,which=1)
plot(fore_roll,which=2)
```

Since we plotted everything except the last 500 data points, we can see the rolling forecast vs. the actual returns. Obviously the main concern we had was that our forecast was significantly flatter than the actual returns, but we did some more research into it. 

> "Forecasting models attempt to disentangle the signal from the noise and only extrapolate the signal, because the noise is - by definition - not forecastable. Therefore, any forecast will look smoother than the original time series." -Stephan Kolassa

By that definition, I think we forecast the general pretty very well from an eye test perspective.

```{r}
par(mfrow=c(1,2))
plot(fore_roll,which=3)
plot(fore_roll,which=4)
```



## Forecasting using Bootstrap

This is a simulation-based forecast where you generate many future paths by resampling residuals. It tells us a distribution of possible future outcomes, not just point estimates, which accounts for model uncertainty and randomness. 

```{r}
par(mfrow=c(1,2))
fore_boot <- ugarchboot(fit_garch_5,data = na.omit(data$Return), method = c("Partial", "Full")[1], n.ahead = 20, n.bootpred = 500)
plot(fore_boot,which=2)
plot(fore_boot,which=3)
```

```{r}
head(sigma(forecast))
```

The first few conditional volatility forecasts from our forecast model imply a gradual decrease in volatility over the next 6 periods. If we circle back to the model selection, we somewhat expected this because of our high persistence earlier. 

# Conclusion
We used a ARMA(3,2)-eGARCH(1,1) model to predict AAPL's stock price movements. The model was selected as it had the lowest AIC of the 8 models we tested. The 8 models had common AR(p)-MA(q) parameters given the ARC and PARC graphs. While our forecasted stock price varies from the observed stock price, this was largely the result of recent market events - tariffs and geopolitical conflict between AAPL's two most important markets (US & China). With the selected features, there was no way to incorporate these impacts based on historical time series data. However, a more complex model that utilizes real time sentiment analysis or other real time market data could improve the model. 

# References
- https://rpubs.com/Mahmud_Hasan/778532
- https://online.stat.psu.edu/stat510/lesson/11/11.1
- https://www.quantstart.com/articles/Autoregressive-Moving-Average-ARMA-p-q-Models-for-Time-Series-Analysis-Part-3/
- https://stats.stackexchange.com/questions/378817/auto-arima-forecasting-same-value-continuously-for-future-part-in-r/378826#378826

